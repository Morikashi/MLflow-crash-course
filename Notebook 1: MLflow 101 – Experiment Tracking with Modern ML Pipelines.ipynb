{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow 101: Experiment Tracking with Modern ML Pipelines\n",
    "\n",
    "Welcome to the first notebook in our MLflow series! This notebook is designed to introduce you to the basics of MLflow, focusing on **experiment tracking** in modern machine learning pipelines. We aim to keep things simple and clear, ensuring you get comfortable with the core concepts of MLflow. \n",
    "\n",
    "**Note**: This notebook keeps things simple to get you comfortable with MLFlow’s core concepts. Starting from Notebook 2, we’ll dive into more exciting, cutting-edge machine learning and generative AI challenges!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to MLflow](#introduction-to-mlflow)\n",
    "2. [Setting up Your MLflow Environment](#setting-up-mlflow)\n",
    "3. [Loading and Preparing a Modern Dataset: OMat24](#loading-and-preparing-dataset)\n",
    "4. [Building a Modern ML Model: XGBoost](#building-a-modern-ml-model)\n",
    "5. [Tracking Your First Experiment with MLflow](#tracking-experiments-with-mlflow)\n",
    "6. [Exploring and Comparing Experiment Runs via MLflow UI](#comparing-experiment-runs)\n",
    "7. [Key Takeaways](#key-takeaways)\n",
    "8. [Engaging Resources and Further Reading](#resources-and-further-reading)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to MLflow\n",
    "\n",
    "MLflow is an open-source platform designed to manage the end-to-end machine learning lifecycle. This includes:\n",
    "- **Experimentation:** Tracking parameters, code, data, and results.\n",
    "- **Reproducibility:** Ensuring that your experiments and results can be consistently replicated.\n",
    "- **Deployment:** Packaging and deploying models to various serving environments.\n",
    "- **Model Registry:** A centralized hub to manage, version, and stage your models.\n",
    "\n",
    "![MLflow Logo](https://www.the-odd-dataguy.com/images/posts/20191113/cover.jpg)\n",
    "\n",
    "In this initial notebook, our primary focus will be on **MLflow Tracking**. This component allows you to log parameters, code versions, metrics, and output files when running your machine learning code. It provides a UI to visualize and compare results from different runs, which is invaluable for iterating on models and understanding what works.\n",
    "\n",
    "Think of MLflow Tracking as your sophisticated lab notebook for every experiment you conduct. It helps you answer questions like:\n",
    "- *What were the exact parameters used for that high-performing model?*\n",
    "- *How did changing a particular feature affect the outcome?*\n",
    "- *Which version of the code produced this specific result?*\n",
    "\n",
    "By the end of this notebook, you'll be able to set up MLflow, run a simple ML experiment, log its details, and know how to view them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up Your MLflow Environment\n",
    "\n",
    "First things first, let's get MLflow installed and imported into our notebook. We'll also set up a **tracking URI**. The tracking URI tells MLflow where to store your experiment data (runs, parameters, metrics, artifacts, etc.). For simplicity, we'll use a local directory named `mlruns` which MLflow will create automatically in your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLflow if you haven't already. \n",
    "# We use 'pip install --quiet' to suppress extensive output for a cleaner notebook.\n",
    "!pip install --quiet mlflow\n",
    "\n",
    "# Import the MLflow library\n",
    "import mlflow\n",
    "import mlflow.sklearn # For scikit-learn flavor, though we'll use XGBoost directly\n",
    "\n",
    "# Set the tracking URI. MLflow will store tracking data in a local './mlruns' directory.\n",
    "# If you have a dedicated MLflow tracking server, you would put its URI here (e.g., http://your-mlflow-server:5000).\n",
    "mlflow.set_tracking_uri('mlruns') # Using a local directory for simplicity\n",
    "\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these few lines, MLflow is ready to start tracking our experiments. The `mlruns` directory will be created once we log our first experiment. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading and Preparing a Modern Dataset: OMat24\n",
    "\n",
    "For our first MLflow experiment, we'll use the **Meta Open Materials 2024 (OMat24)** dataset. This is a rich, scientific dataset published in 2024, containing results of Density Functional Theory (DFT) computations for a vast number of materials. It's an excellent example of a modern dataset relevant for practical ML applications in materials science and beyond.\n",
    "\n",
    "We'll load it directly from Hugging Face using the `datasets` library. To keep this introductory notebook nimble, we'll use the 'small' configuration of the dataset and only take a small slice of its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet datasets pandas # Install Hugging Face datasets and pandas\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load a small subset of the OMat24 dataset ('small' configuration, first 1000 training samples)\n",
    "try:\n",
    "    omat_dataset = load_dataset('facebook/OMAT24', 'small', split='train[:1000]')\n",
    "    print(\"Successfully loaded OMat24 dataset.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load dataset: {e}\")\n",
    "    print(\"Please ensure you have internet connectivity and the dataset name is correct.\")\n",
    "    # As a fallback for environments without internet or if OMAT24 is too large/problematic quickly:\n",
    "    # We can create a dummy dataset for demonstration purposes.\n",
    "    print(\"Using a dummy dataset for demonstration.\")\n",
    "    data = {\n",
    "        'feature1': [i for i in range(1000)],\n",
    "        'feature2': [i*2 for i in range(1000)],\n",
    "        'feature3': [i*0.5 for i in range(1000)],\n",
    "        'formation_energy_per_atom': [i*1.5 + 0.1*(-1)**i for i in range(1000)]\n",
    "    }\n",
    "    omat_dataset = pd.DataFrame(data)\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation\n",
    "if not isinstance(omat_dataset, pd.DataFrame):\n",
    "    df = omat_dataset.to_pandas()\n",
    "else:\n",
    "    df = omat_dataset\n",
    "\n",
    "print(\"\\nDataset Preview (First 5 rows):\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "\n",
    "# For OMat24, let's select a few numerical features and our target variable.\n",
    "# The actual OMat24 dataset has many features. We'll pick a few simple ones for this example.\n",
    "# Target: 'formation_energy_per_atom' (a common target in materials science)\n",
    "# Features: We'll try to use some lattice parameters if they exist and are numeric.\n",
    "# If using the dummy dataset, these specific feature names will match.\n",
    "\n",
    "potential_features = ['lattice_vector_1_x', 'lattice_vector_1_y', 'lattice_vector_1_z', \n",
    "                      'lattice_vector_2_x', 'lattice_vector_2_y', 'lattice_vector_2_z',\n",
    "                      'feature1', 'feature2', 'feature3'] # Add dummy features for fallback\n",
    "target_column = 'formation_energy_per_atom'\n",
    "\n",
    "available_features = [f for f in potential_features if f in df.columns and pd.api.types.is_numeric_dtype(df[f])]\n",
    "\n",
    "if not available_features:\n",
    "    print(\"\\nCould not find suitable numeric features from the predefined list.\")\n",
    "    # Fallback: use any available numeric columns if predefined are not found\n",
    "    available_features = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and col != target_column]\n",
    "    if len(available_features) > 5: # Limit to 5 features for simplicity\n",
    "        available_features = available_features[:5]\n",
    "\n",
    "if not available_features or target_column not in df.columns:\n",
    "    raise ValueError(\"Selected features or target column not found or not numeric in the dataset. Please check the dataset structure.\")\n",
    "\n",
    "print(f\"\\nSelected Features: {available_features}\")\n",
    "print(f\"Target Variable: {target_column}\")\n",
    "\n",
    "X = df[available_features]\n",
    "y = df[target_column]\n",
    "\n",
    "# Basic preprocessing: fill any NaN values with the mean (simple strategy for this intro)\n",
    "X = X.fillna(X.mean())\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "print(\"\\nFeatures (X) shape:\", X.shape)\n",
    "print(\"Target (y) shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded our data, selected relevant features and our target ('formation_energy_per_atom'). This is a regression task: predicting a continuous value. The data preparation steps here are minimal to keep focus on MLflow. In real-world scenarios, this stage would involve more extensive exploratory data analysis (EDA) and feature engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Modern ML Model: XGBoost\n",
    "\n",
    "Instead of a simplistic model, let's use **XGBoost (Extreme Gradient Boosting)**. XGBoost is a powerful and widely-used gradient boosting library that excels in many tabular data competitions and real-world applications. It's known for its performance and scalability.\n",
    "\n",
    "We'll train an `XGBRegressor` model to predict the `formation_energy_per_atom` based on the selected lattice features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet xgboost scikit-learn # Install XGBoost and scikit-learn\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "\n",
    "# Initialize and train the XGBoost Regressor model\n",
    "# We'll use a few common hyperparameters. More advanced tuning will be covered later.\n",
    "params = {\n",
    "    'objective': 'reg:squarederror', # Objective function for regression\n",
    "    'n_estimators': 100,             # Number of boosting rounds (trees)\n",
    "    'learning_rate': 0.1,            # Step size shrinkage\n",
    "    'max_depth': 3,                  # Maximum depth of a tree\n",
    "    'random_state': 42               # For reproducibility\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance on Validation Set:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (R2 Score): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've trained a sophisticated XGBoost model and evaluated its performance. Now, how can MLflow help us keep track of this process, especially if we want to try different parameters, features, or even models?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tracking Your First Experiment with MLflow\n",
    "\n",
    "This is where MLflow shines. We'll use `mlflow.start_run()` to create a new MLflow run. Within the context of this run, we can log:\n",
    "\n",
    "- **Parameters (`mlflow.log_param()`):** Key-value pairs representing input parameters to our model training, like hyperparameter values (`learning_rate`, `n_estimators`).\n",
    "- **Metrics (`mlflow.log_metric()`):** Key-value pairs representing model performance metrics, like MSE or R2 score. Metrics can be updated throughout a run (e.g., logging loss at each epoch).\n",
    "- **Artifacts (`mlflow.log_artifact()` or specific `mlflow.<flavor>.log_model()`):** Larger files, such as the trained model itself, images (like plots), or data files.\n",
    "\n",
    "Let's re-run our training, but this time, wrapped in an MLflow run context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "experiment_name = \"OMat24_Material_Property_Prediction\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Initial_Run\") as run: # You can give your run a custom name\n",
    "    print(f\"Starting MLflow Run: {run.info.run_name}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Experiment ID: {run.info.experiment_id}\")\n",
    "    \n",
    "    # Log parameters used for this run\n",
    "    mlflow.log_params(params) # Log all parameters from the dict\n",
    "    mlflow.log_param(\"train_test_split_random_state\", 42)\n",
    "    mlflow.log_param(\"dataset_subset_size\", len(df))\n",
    "    mlflow.log_param(\"features_used\", \", \".join(available_features))\n",
    "\n",
    "    # Re-train the model (or you could train it inside the 'with' block from scratch)\n",
    "    # For this example, we'll assume the model 'model' and metrics 'mse', 'r2' are from the cell above.\n",
    "    # In a typical workflow, training happens INSIDE the mlflow.start_run() context.\n",
    "    # Let's re-run the training and evaluation to be self-contained within the run for clarity.\n",
    "    \n",
    "    model_in_run = xgb.XGBRegressor(**params)\n",
    "    model_in_run.fit(X_train, y_train)\n",
    "    y_pred_in_run = model_in_run.predict(X_val)\n",
    "    mse_in_run = mean_squared_error(y_val, y_pred_in_run)\n",
    "    r2_in_run = r2_score(y_val, y_pred_in_run)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse_in_run)\n",
    "    mlflow.log_metric(\"r2_score\", r2_in_run)\n",
    "    print(f\"Logged Metrics: MSE={mse_in_run:.4f}, R2={r2_in_run:.4f}\")\n",
    "\n",
    "    # Log the trained model using MLflow's scikit-learn flavor (XGBoost is scikit-learn compatible)\n",
    "    # This saves the model in a format MLflow understands, allowing for easy loading later.\n",
    "    # The 'artifact_path' is a name for the model within this run's artifacts.\n",
    "    mlflow.xgboost.log_model(model_in_run, artifact_path=\"xgboost-model\")\n",
    "    print(f\"Model logged under path: xgboost-model\")\n",
    "\n",
    "    # You can also log arbitrary files as artifacts\n",
    "    # For example, let's log the list of features used as a text file\n",
    "    with open(\"features.txt\", \"w\") as f:\n",
    "        for feature in available_features:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    mlflow.log_artifact(\"features.txt\", artifact_path=\"feature_info\")\n",
    "    print(f\"Logged 'features.txt' artifact to 'feature_info' directory.\")\n",
    "\n",
    "    print(f\"\\nMLflow Run {run.info.run_name} completed and logged.\")\n",
    "\n",
    "print(\"\\nCheck the 'mlruns' directory in your file system. It should now contain experiment data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We've successfully logged our first experiment. MLflow has captured the parameters we used, the performance metrics (MSE and R2 score), and even the trained XGBoost model itself, along with our feature list. All this information is now neatly organized and associated with a unique run ID within the specified experiment.\n",
    "\n",
    "If you were to change a hyperparameter (e.g., `learning_rate` to 0.05) and re-run the cell above (perhaps with a new `run_name`), MLflow would create a *new run* with the updated parameters and corresponding metrics. This is the core of experiment tracking: systematically recording each attempt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploring and Comparing Experiment Runs via MLflow UI\n",
    "\n",
    "One of the most powerful features of MLflow is its User Interface (UI). The UI allows you to visualize, search, and compare your experiment runs graphically.\n",
    "\n",
    "To launch the MLflow UI, open your terminal or command prompt, navigate to the directory **containing your `mlruns` folder** (which is likely the same directory where this notebook is saved), and run the following command:\n",
    "\n",
    "`mlflow ui`\n",
    "\n",
    "This will start a local web server, typically at `http://localhost:5000` (or `http://127.0.0.1:5000`). Open this URL in your web browser.\n",
    "\n",
    "![MLflow UI Example](https://blog.min.io/content/images/2025/03/Screenshot-2025-03-10-at-3.30.33-PM.png)\n",
    "*Image Source: MLflow Documentation. Your UI will show the experiment we just ran.* \n",
    "\n",
    "**What to explore in the MLflow UI:**\n",
    "\n",
    "- **Experiments List:** On the left, you'll see your experiment (`OMat24_Material_Property_Prediction`). Clicking on it will show all associated runs.\n",
    "- **Runs Table:** For each run, you'll see key information like start time, duration, parameters, and metrics you logged.\n",
    "- **Run Details:** Click on a specific run (e.g., `XGBoost_Initial_Run`) to see more details:\n",
    "    - **Parameters:** All logged hyperparameters.\n",
    "    - **Metrics:** Logged metrics like MSE and R2. You can even see plots if metrics are logged over time (e.g., training epochs).\n",
    "    - **Artifacts:** Any logged artifacts, including the `xgboost-model` directory (containing your model files) and the `feature_info` directory with `features.txt`.\n",
    "- **Comparing Runs:** If you run the experiment multiple times (e.g., with different hyperparameters), you can select multiple runs from the table and click \"Compare.\" This provides a side-by-side comparison of their parameters and metrics, making it easy to see what changes led to better (or worse) performance.\n",
    "\n",
    "**Spend some time navigating the UI. It's very intuitive!** Try changing a parameter in the code cell for section 5 (e.g., `n_estimators` to 150 or `learning_rate` to 0.05), give the run a new name (e.g., `XGBoost_Run_More_Estimators`), and re-run it. Then, go back to the MLflow UI, refresh, and see how you can compare these two runs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "In this first notebook, you've learned the essentials of MLflow experiment tracking:\n",
    "\n",
    "- **What MLflow is:** An open-source platform for the MLOps lifecycle.\n",
    "- **Setting up MLflow:** Installing MLflow and setting a tracking URI (local `mlruns` directory for now).\n",
    "- **Core Tracking Concepts:**\n",
    "    - **Experiments:** A way to organize runs for a specific problem (e.g., `OMat24_Material_Property_Prediction`).\n",
    "    - **Runs:** Single executions of your ML code.\n",
    "    - **Parameters:** Inputs to your run (e.g., hyperparameters).\n",
    "    - **Metrics:** Outputs/results of your run (e.g., MSE, R2 score).\n",
    "    - **Artifacts:** Any other files you want to save (e.g., trained models, data files, plots).\n",
    "- **Logging with MLflow:** Using `mlflow.set_experiment()`, `mlflow.start_run()`, `mlflow.log_param()`, `mlflow.log_params()`, `mlflow.log_metric()`, `mlflow.xgboost.log_model()`, and `mlflow.log_artifact()`.\n",
    "- **MLflow UI:** Launching and using the UI to view, search, and compare experiments and runs.\n",
    "\n",
    "This foundation is crucial. As we move to more complex models and tasks in subsequent notebooks, including those involving Large Language Models (LLMs) and Generative AI, these MLflow tracking skills will be indispensable for managing the increased complexity and iteration involved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Engaging Resources and Further Reading\n",
    "\n",
    "Want to dive deeper? Here are some excellent resources:\n",
    "\n",
    "- **MLflow Official Documentation:**\n",
    "    - [MLflow Quickstart](https://mlflow.org/docs/latest/getting-started/index.html)\n",
    "    - [MLflow Tracking Guide](https://mlflow.org/docs/latest/tracking.html)\n",
    "    - [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)\n",
    "- **Dataset Used:**\n",
    "    - [Meta Open Materials 2024 (OMat24) on Hugging Face](https://huggingface.co/datasets/facebook/OMAT24)\n",
    "    - [OMat24 Paper (if interested in the science)](https://ai.meta.com/blog/meta-open-materials-omat-dataset-ai-accelerate-discovery/)\n",
    "- **Model Library Used:**\n",
    "    - [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/)\n",
    "- **Community & Code:**\n",
    "    - [MLflow GitHub Repository](https://github.com/mlflow/mlflow)\n",
    "    - [MLflow Community Slack (via LF AI & Data Foundation)](https://lfaidata.foundation/projects/mlflow/)\n",
    "\n",
    "--- \n",
    "\n",
    "Thank you for working through this first notebook! We hope you're excited about the power and simplicity of MLflow for experiment tracking. \n",
    "\n",
    "**Coming Up Next:** Get ready for more advanced MLflow features, including hyperparameter optimization, model registry, and applications in the realm of LLMs and GenAI. Stay tuned!",
    "\n",
    "![Keep Learning](https://memento.epfl.ch/image/23136/1440x810.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
