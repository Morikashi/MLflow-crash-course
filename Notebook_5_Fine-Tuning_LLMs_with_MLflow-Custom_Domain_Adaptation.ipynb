{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow 05: Fine-Tuning Qwen3-0.6B with MLflow - Custom Domain Adaptation\n",
    "\n",
    "Welcome to the fifth notebook in our MLflow series! In our previous notebooks, we've covered MLflow fundamentals, hyperparameter optimization, model registry, and even an introduction to RAG. Now, we're diving deep into customizing a cutting-edge, efficient Large Language Model: **Qwen3-0.6B**.\n",
    "\n",
    "This notebook focuses on **Fine-Tuning** this modern LLM to adapt it for a specific domain â€“ generating creative recipes. Fine-tuning allows us to teach a pre-trained model new behaviors, styles, or specialized knowledge, often leading to better performance on niche tasks than a general-purpose model.\n",
    "\n",
    "We'll be using:\n",
    "- **`Qwen/Qwen3-0.6B`**: A recent, highly capable, and compute-efficient 0.6 billion parameter model from Alibaba's Qwen3 series.\n",
    "- **Parameter-Efficient Fine-Tuning (PEFT)** with **Low-Rank Adaptation (LoRA)** to make fine-tuning accessible.\n",
    "- **Hugging Face `transformers`**, **`peft`**, and **`trl`** (for `SFTTrainer`) libraries.\n",
    "- **MLflow** to meticulously track our experiments, log configurations, model adapters, and qualitative results, ensuring reproducibility and comparability.\n",
    "\n",
    "![Fine-tuning Concept](https://a.storyblok.com/f/139616/1200x800/5d759e4410/fine-tuning.webp)\n",
    "\n",
    "Let's embark on tailoring the Qwen3-0.6B model for our recipe generation task!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Why Fine-Tune LLMs? Focus on Domain Adaptation](#why-fine-tune)\n",
    "2. [Introducing Qwen3-0.6B and Our Dataset](#intro-qwen3-dataset)\n",
    "3. [Setting Up the Fine-Tuning Environment](#setting-up-environment-qwen3)\n",
    "    - [Installing Libraries (Qwen3 Specifics)](#installing-libraries-qwen3)\n",
    "    - [GPU Considerations](#gpu-considerations-qwen3)\n",
    "    - [Configuring MLflow](#configuring-mlflow-qwen3)\n",
    "4. [Data Preparation for Supervised Fine-Tuning (SFT)](#data-preparation-sft-qwen3)\n",
    "    - [Loading and Inspecting the Recipe Dataset](#loading-inspecting-dataset-qwen3)\n",
    "    - [Formatting and Tokenization for Qwen3](#formatting-tokenization-qwen3)\n",
    "5. [Fine-Tuning Qwen3-0.6B with LoRA, `transformers`, and `trl`](#fine-tuning-qwen3-lora)\n",
    "    - [Loading the Qwen3-0.6B Base Model (with Quantization)](#loading-qwen3-base-model)\n",
    "    - [Configuring LoRA for Qwen3](#configuring-lora-qwen3)\n",
    "    - [Setting up Training Arguments](#setting-up-training-args-qwen3)\n",
    "    - [Initializing and Running the `SFTTrainer`](#initializing-sfttrainer-qwen3)\n",
    "6. [Integrating Qwen3 Fine-Tuning with MLflow](#integrating-qwen3-ft-mlflow)\n",
    "    - [Logging Parameters, Metrics, and Adapters](#logging-qwen3-ft-params-metrics-artifacts)\n",
    "7. [Qualitative Evaluation of the Fine-Tuned Qwen3 Model](#qualitative-evaluation-qwen3)\n",
    "    - [Loading the Fine-Tuned Qwen3 Adapter](#loading-qwen3-ft-adapter)\n",
    "    - [Generating Sample Recipe Responses (Qwen3 Specifics)](#generating-qwen3-sample-responses)\n",
    "8. [Exploring Qwen3 Fine-Tuning Runs in MLflow UI](#exploring-qwen3-ft-mlflow-ui)\n",
    "9. [Key Takeaways for Qwen3 Fine-Tuning](#key-takeaways-qwen3-ft)\n",
    "10. [Engaging Resources and Further Reading (Qwen3 Focus)](#resources-and-further-reading-qwen3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Fine-Tune LLMs? Focus on Domain Adaptation\n",
    "\n",
    "Fine-tuning allows us to specialize a general pre-trained LLM for specific tasks or domains. While large models are powerful, fine-tuning can unlock superior performance, style, and knowledge relevant to your unique needs.\n",
    "\n",
    "**Key Benefits for Domain Adaptation:**\n",
    "- **Specialized Vocabulary & Nuances:** Teach the model the specific language, jargon, and subtle understanding of a particular field (e.g., generating recipes, medical report summaries, legal document analysis).\n",
    "- **Style & Tone Alignment:** Adapt the model to generate text in a desired voice, tone (formal, casual, enthusiastic), or format (e.g., recipe steps, JSON outputs, poetic verse).\n",
    "- **Improved Task Performance:** Enhance capabilities for tasks where the base model might be too general (e.g., generating highly specific types of creative content or following complex, domain-specific instructions).\n",
    "\n",
    "For this notebook, our goal is to adapt `Qwen3-0.6B` to become proficient at generating creative and coherent recipes.\n",
    "\n",
    "**Parameter-Efficient Fine-Tuning (PEFT):** Techniques like LoRA drastically reduce the computational resources and memory required for fine-tuning by only updating a small fraction of the model's parameters. This makes fine-tuning accessible even for very large models on consumer-grade hardware.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducing Qwen3-0.6B and Our Dataset\n",
    "\n",
    "**Base Model: `Qwen/Qwen3-0.6B`**\n",
    "We'll be fine-tuning `Qwen/Qwen3-0.6B`. This is the latest (as of May 2025) 0.6 billion parameter model in the Qwen3 series from Alibaba. \n",
    "Key features:\n",
    "- **Size:** 0.6B parameters (0.44B non-embedding).\n",
    "- **Architecture:** Causal Language Model, 28 layers, GQA (16 heads for Q, 8 for KV).\n",
    "- **Context Length:** Supports up to 32,768 tokens.\n",
    "- **Training:** Pre-trained and post-trained (instruction/chat tuned).\n",
    "- **Highlights:** Strong reasoning, instruction-following, multilingual support, and agent capabilities.\n",
    "\n",
    "Its relatively small size combined with strong capabilities makes it an excellent candidate for efficient fine-tuning.\n",
    "\n",
    "**Dataset for Fine-Tuning (Recipe Generation):**\n",
    "We will again use the `alignment-handbook/recipe_instructions` dataset. This dataset provides prompt-response pairs for generating recipes, which is ideal for our domain adaptation task. The typical format is `<s>Human: [USER_PROMPT]</s><s>Assistant: [MODEL_RESPONSE]</s>`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Up the Fine-Tuning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Libraries (Qwen3 Specifics)\n",
    "A crucial requirement for Qwen3 models is a recent version of the `transformers` library (`>=4.51.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet mlflow \"transformers>=4.51.0\" datasets peft trl bitsandbytes sentencepiece accelerate\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset # Ensure Dataset is imported\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "import transformers\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "import peft\n",
    "print(f\"PEFT Version: {peft.__version__}\")\n",
    "import trl\n",
    "print(f\"TRL Version: {trl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Considerations\n",
    "Even with PEFT and quantization, fine-tuning Qwen3-0.6B benefits significantly from a GPU. A GPU with ~8-16GB VRAM should be manageable for LoRA fine-tuning with appropriate batch sizes and sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    print(\"CUDA not available. Fine-tuning will be very slow or impossible on CPU.\")\n",
    "    device = 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('mlruns')\n",
    "experiment_name = \"LLM_FineTuning_RecipeBot_Qwen3_0.6B\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"MLflow Experiment set to: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation for Supervised Fine-Tuning (SFT)\n",
    "We'll prepare the `alignment-handbook/recipe_instructions` dataset for supervised fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Inspecting the Recipe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"alignment-handbook/recipe_instructions\"\n",
    "try:\n",
    "    raw_dataset = load_dataset(dataset_name, split=\"train[:2%]\", trust_remote_code=True) # Using 2% for demo\n",
    "    print(f\"Loaded {len(raw_dataset)} samples from {dataset_name}.\")\n",
    "    print(\"\\nSample entry:\")\n",
    "    print(raw_dataset[0]['text'])\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Creating a dummy dataset for fallback.\")\n",
    "    dummy_texts = [\n",
    "        \"<s>Human: Give me a recipe for chocolate chip cookies.</s><s>Assistant: Ingredients: 1 cup butter, 3/4 cup sugar, 3/4 cup brown sugar, 2 eggs, 1 tsp vanilla, 2 1/4 cups flour, 1 tsp baking soda, 1/2 tsp salt, 2 cups chocolate chips. Instructions: Cream butter and sugars. Beat in eggs and vanilla. Combine dry ingredients, add to wet. Stir in chips. Bake at 375Â°F for 9-11 mins.</s>\",\n",
    "        \"<s>Human: How to make a simple tomato soup?</s><s>Assistant: Ingredients: 1 tbsp olive oil, 1 onion chopped, 2 cloves garlic minced, 1 can (28oz) crushed tomatoes, 2 cups vegetable broth, 1/2 cup heavy cream (optional), salt and pepper to taste. Instructions: SautÃ© onion and garlic in oil. Add tomatoes and broth, simmer 15 mins. Blend until smooth. Stir in cream if using. Season.</s>\"\n",
    "    ]\n",
    "    raw_dataset = Dataset.from_dict({\"text\": dummy_texts})\n",
    "    print(f\"Using dummy dataset with {len(raw_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting and Tokenization for Qwen3\n",
    "Qwen models, like many others, require specific tokenization. `SFTTrainer` handles much of the complexity if the data is a single text field containing the prompt and response. The `SFTTrainer` from `trl` can directly handle datasets where each entry is a string containing the full conversation turn (prompt + response). It will take care of formatting and masking labels for the prompt part during training.\n",
    "\nWe need to load the tokenizer for our chosen base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"Qwen/Qwen3-0.6B\" # Using the instruct/chat version\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "\n",
    "# Qwen tokenizers might not have a default pad_token. Setting it to eos_token is a common strategy.\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "    # Some Qwen versions might prefer unk_token or a specific pad token if defined.\n",
    "    # For Qwen3, eos_token is generally fine for padding in fine-tuning.\n",
    "tokenizer.padding_side = \"right\" # Crucial for causal LMs\n",
    "\n",
    "print(f\"Tokenizer for {base_model_name} loaded. Pad token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id}), EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "dataset_text_field = \"text\"\n",
    "train_dataset = raw_dataset\n",
    "print(f\"Using {len(train_dataset)} samples for fine-tuning with Qwen3-0.6B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Preprocessing](https://thumbs.dreamstime.com/b/four-components-data-preprocessing-components-data-preprocessing-117562111.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-Tuning Qwen3-0.6B with LoRA, `transformers`, and `trl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Qwen3-0.6B Base Model (with Quantization)\n",
    "We'll use 4-bit quantization for memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(\"Loading Qwen3-0.6B base model with 4-bit quantization...\")\n",
    "try:\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(f\"Base model {base_model_name} loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading base model: {e}\")\n",
    "    raise e\n",
    "\n",
    "base_model.config.tokenizer_class = tokenizer.__class__.__name__\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.config.use_cache = False # Important for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring LoRA for Qwen3\n",
    "Based on community findings for Qwen3 models, a LoRA rank of 8 with alpha 16 seems like a good, efficient starting point. The target modules are typical for many transformer architectures.\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,              # LoRA rank\n",
    "    lora_alpha=16,    # LoRA alpha (often 2*r)\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"], # Common for Qwen3\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(base_model, lora_config)\n",
    "print(\"\\nPEFT model created with LoRA adapters for Qwen3-0.6B.\")\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./qwen3_0.6b_recipe_finetuned_adapters\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2, # Adjust based on VRAM\n",
    "    gradient_accumulation_steps=4, # Effective batch size = 8\n",
    "    learning_rate=2e-4,            # Common for LoRA\n",
    "    num_train_epochs=1,            # 1 epoch for demo\n",
    "    logging_steps=10,              # Log more frequently for small datasets\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"adamw_bnb_8bit\",        # 8-bit Adam optimizer for memory efficiency\n",
    "    warmup_steps=10,\n",
    "    fp16=True if torch.cuda.is_available() and not torch.cuda.is_bf16_supported() else False,\n",
    "    bf16=True if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else False,\n",
    "    report_to=\"mlflow\",\n",
    "    # max_steps=50, # For very quick demo runs instead of epochs\n",
    ")\n",
    "\n",
    "print(\"\\nTrainingArguments configured for Qwen3-0.6B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Running the ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = (\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    dataset_text_field=dataset_text_field,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=1024, # Qwen3-0.6B supports long contexts, but 1024/2048 is fine for recipes & VRAM\n",
    "    # packing=True, # Can improve efficiency if dataset has many short sequences\n",
    ")\n",
    "\n",
    "print(\"\\n initialized for Qwen3-0.6B. Starting fine-tuning...\")\n",
    "train_result = None\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        train_result = trainer.train()\n",
    "        print(\"Fine-tuning completed.\")\n",
    "        trainer.save_model(os.path.join(output_dir, \"final_adapter\"))\n",
    "        print(f\"Final Qwen3-0.6B adapter model saved to {os.path.join(output_dir, 'final_adapter')}\")\n",
    "    else:\n",
    "        print(\"Skipping training as CUDA is not available.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Qwen3-0.6B training: {e}\")\n",
    "    raise e\n",
    "\n",
    "del base_model\n",
    "del peft_model\n",
    "del trainer\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Cleaned up Qwen3 models from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "## 6. Integrating Qwen3 Fine-Tuning with MLflow\n",
   "\n",
   "The `SFTTrainer` (with `report_to=\"mlflow\"`) automatically logs training metrics to an active MLflow run. We'll ensure other important configuration details and the final adapter are also logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_run = mlflow.last_active_run()\n",
    "if active_run:\n",
    "    print(f\"Active MLflow Run ID for Qwen3 FT: {active_run.info.run_id}\")\n",
    "    with mlflow.start_run(run_id=active_run.info.run_id, nested=False) as run:\n",
    "        mlflow.log_param(\"base_model_name\", base_model_name)\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        mlflow.log_param(\"num_train_samples\", len(train_dataset) if train_dataset else 0)\n",
    "        mlflow.log_params({\n",
    "            \"lora_r\": lora_config.r,\n",
    "            \"lora_alpha\": lora_config.lora_alpha,\n",
    "            \"lora_dropout\": lora_config.lora_dropout,\n",
    "            \"lora_target_modules\": \",\".join(lora_config.target_modules) if hasattr(lora_config, 'target_modules') and lora_config.target_modules is not None else 'N/A'\n",
    "        })\n",
    "        mlflow.log_param(\"quantization_config\", str(quantization_config.to_dict()))\n",
    "        mlflow.log_param(\"max_seq_length_sfttrainer\", 1024)\n",
    "\n",
    "        final_adapter_path_from_trainer = os.path.join(output_dir, \"final_adapter\")\n",
    "        if os.path.exists(final_adapter_path_from_trainer):\n",
    "            mlflow.log_artifacts(final_adapter_path_from_trainer, artifact_path=\"fine_tuned_qwen3_lora_adapter\")\n",
    "            print(f\"Logged final Qwen3 LoRA adapter from '{final_adapter_path_from_trainer}' to MLflow run {run.info.run_id}.\")\n",
    "        else:\n",
    "            print(f\"Final Qwen3 adapter path '{final_adapter_path_from_trainer}' not found.\")\n",
    "        \n",
    "        mlflow.set_tag(\"task\", \"RecipeGeneration_Qwen3\")\n",
    "        mlflow.set_tag(\"architecture\", \"Qwen3-0.6B_LoRA\")\n",
    "else:\n",
    "    print(\"No active MLflow run found for Qwen3 FT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLFlow Tracking](https://media.datacamp.com/cms/google/ad_4nxekg7ftko2m1hrkr-bwr-kq5gzr9wfugs9spjvgmoca-yykxhhepgcwxxo9yrbhu4barnqvmx6psn9scgku1car3lvlhltqnada0i9m7cg_glbdf5ty3lu4t3pcyxel6dyh1n84fcsl3xqvgdktujpvrian.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Qualitative Evaluation of the Fine-Tuned Qwen3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Fine-Tuned Qwen3 Adapter\n",
    "We load the quantized base Qwen3-0.6B model again and apply our trained LoRA weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = os.path.join(output_dir, \"final_adapter\")\n",
    "merged_model_qwen3 = None\n",
    "base_model_for_qwen3_eval = None\n",
    "\n",
    "if not os.path.exists(os.path.join(adapter_path, \"adapter_model.safetensors\")) and not os.path.exists(os.path.join(adapter_path, \"adapter_model.bin\")):\n",
    "    print(f\"Fine-tuned Qwen3 adapter not found at {adapter_path}. Skipping qualitative evaluation.\")\n",
    "else:\n",
    "    print(f\"Qwen3 adapter found at {adapter_path}. Loading for evaluation.\")\n",
    "    eval_device_map = \"auto\" if torch.cuda.is_available() else {\"\": \"cpu\"}\n",
    "    \n",
    "    base_model_for_qwen3_eval = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=eval_device_map,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    # Reload tokenizer to ensure it's clean, though it should be the same\n",
    "    eval_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "    if eval_tokenizer.pad_token is None: eval_tokenizer.pad_token = eval_tokenizer.eos_token\n",
    "    eval_tokenizer.padding_side = \"right\"\n",
    "\n",
    "    merged_model_qwen3 = PeftModel.from_pretrained(base_model_for_qwen3_eval, adapter_path, is_trainable=False)\n",
    "    merged_model_qwen3.eval()\n",
    "    print(\"Fine-tuned Qwen3-0.6B model (base + adapter) loaded for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Sample Recipe Responses (Qwen3 Specifics)\n",
    "Let's prompt our fine-tuned Qwen3-0.6B. The Qwen3 model card mentions using `presence_penalty=1.5` if significant endless repetitions occur. We'll include it as an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prompts_qwen3 = [\n",
    "    \"<s>Human: I need a creative recipe for a gluten-free pasta dish.</s><s>Assistant:\",\n",
    "    \"<s>Human: Can you suggest a quick and easy dessert recipe using apples?</s><s>Assistant:\",\n",
    "    \"<s>Human: What's a good recipe for a spicy vegetarian curry?</s><s>Assistant:\"\n",
    "]\n",
    "\n",
    "generated_responses_qwen3_text = \"\"\n",
    "\n",
    "if merged_model_qwen3 and eval_tokenizer:\n",
    "    print(\"\\nGenerating responses with the fine-tuned Qwen3-0.6B model...\")\n",
    "    for prompt_text in sample_prompts_qwen3:\n",
    "        print(f\"\\nPrompt: {prompt_text}\")\n",
    "        inputs = eval_tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(merged_model_qwen3.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = merged_model_qwen3.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=256,\n",
    "                eos_token_id=eval_tokenizer.eos_token_id,\n",
    "                pad_token_id=eval_tokenizer.pad_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                # presence_penalty=1.1, # Optional: Qwen3 specific, use if repetitions are an issue\n",
    "            )\n",
    "        response_text_full = eval_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        assistant_marker = \"<s>Assistant:\"\n",
    "        if assistant_marker in response_text_full:\n",
    "            actual_response = response_text_full.split(assistant_marker, 1)[1].strip()\n",
    "        else:\n",
    "            actual_response = response_text_full.replace(prompt_text.replace(assistant_marker, \"\").strip(), \"\").strip()\n",
    "        \n",
    "        print(f\"Response: {actual_response}\")\n",
    "        generated_responses_qwen3_text += f\"Prompt: {prompt_text}\\nResponse: {actual_response}\\n---\\n\"\n",
    "        \n",
    "    active_run_for_qwen3_eval = mlflow.last_active_run()\n",
    "    if active_run_for_qwen3_eval:\n",
    "        with mlflow.start_run(run_id=active_run_for_qwen3_eval.info.run_id, nested=False) as run:\n",
    "            mlflow.log_text(generated_responses_qwen3_text, \"sample_generations_qwen3_finetune.txt\")\n",
    "            print(\"\\nLogged Qwen3 sample generations to MLflow.\")\n",
    "    \n",
    "    if base_model_for_qwen3_eval is not None: del base_model_for_qwen3_eval\n",
    "    if merged_model_qwen3 is not None: del merged_model_qwen3\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipping Qwen3 sample generation as fine-tuned model or tokenizer is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these responses to what the base `Qwen/Qwen3-0.6B` might generate for the same prompts (if you test it separately) to gauge the effect of fine-tuning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exploring Qwen3 Fine-Tuning Runs in MLflow UI\n",
    "\n",
    "Launch `mlflow ui` and navigate to the `LLM_FineTuning_RecipeBot_Qwen3_0.6B` experiment.\n",
    "\n",
    "- **Runs, Parameters, Metrics:** As before, examine the logged details. Pay attention to the LoRA config (`r=8`, `lora_alpha=16`) and training arguments for Qwen3.\n",
    "- **Artifacts:** \n",
    "    - `fine_tuned_qwen3_lora_adapter`: Contains the Qwen3-specific adapter files.\n",
    "    - `sample_generations_qwen3_finetune.txt`: Your recipe generations from the fine-tuned Qwen3 model.\n",
    "\n",
    "![MLFlow UI](https://mlflow.org/docs/latest/assets/images/oss_registry_3_overview-daec63473b4d7bbf47c559600bf5c35d.png)\n",
    "\n",
    "Using MLflow to compare different LoRA ranks, learning rates, or even different base Qwen3 variants (if available) would be how you'd systematically improve your fine-tuned model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways for Qwen3 Fine-Tuning\n",
    "\n",
    "Fine-tuning `Qwen3-0.6B` offers a path to a customized, efficient LLM:\n",
    "\n",
    "- **Modern & Efficient Base:** `Qwen3-0.6B` provides a strong, recent foundation.\n",
    "- **PEFT/LoRA is Key:** Makes fine-tuning such models feasible on accessible hardware.\n",
    "- **Environment Matters:** Correct `transformers` version (`>=4.51.0`) and careful VRAM management are crucial.\n",
    "- **Community Insights Help:** Leveraging findings (e.g., LoRA rank 8 from) can save experimentation time.\n",
    "- **MLflow for Tracking:** Essential for managing the numerous variables in fine-tuning (LoRA config, training args, model versions, quantization) and comparing outcomes.\n",
    "\n",
    "The recipe generation task is a good example of adapting an LLM for a creative, structured output. The principles here apply to many other domain adaptation scenarios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Engaging Resources and Further Reading (Qwen3 Focus)\n",
    "\n",
    "To learn more about Qwen3 and its fine-tuning:\n",
    "\n",
    "- **Qwen3 Official Resources:**\n",
    "    - [QwenLM GitHub](https://github.com/QwenLM) (Check for Qwen3 specific examples or docs)\n",
    "    - [Qwen3 Model Cards on Hugging Face (e.g., Qwen/Qwen3-0.6B)](https://huggingface.co/Qwen/Qwen3-0.6B)\n",
    "    - [Qwen3 Blog Post](https://qwenlm.github.io/blog/qwen3/) (Provides overview and benchmarks)\n",
    "- **Hugging Face & PEFT/TRL:**\n",
    "    - [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "    - [PEFT Library](https://huggingface.co/docs/peft)\n",
    "    - [TRL Library (SFTTrainer)](https://huggingface.co/docs/trl/sft_trainer)\n",
    "- **Community Examples & Discussions:**\n",
    "    - Search for recent tutorials or discussions on fine-tuning Qwen3 models on platforms like Reddit (e.g., r/LocalLLaMA), Medium, or YouTube. Guides using Unsloth can also offer insights into parameters even if you use pure Hugging Face libraries.\n",
    "\n",
    "--- \n",
    "\n",
    "Excellent work on fine-tuning the Qwen3-0.6B model! This notebook demonstrates how to adapt even the latest LLMs to specific tasks using PEFT and track the process with MLflow.\n",
    "\n",
    "**Coming Up Next (Notebook 6):** Having fine-tuned Qwen3, we'll now shift our focus to evaluating and benchmarking different LLMs. This is crucial for making informed decisions about which model (base or fine-tuned) is best for your application.\n",
    "\n",
    "\n",
    "![Keep Learning](https://memento.epfl.ch/image/23136/1440x810.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
